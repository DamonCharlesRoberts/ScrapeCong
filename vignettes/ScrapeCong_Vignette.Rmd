---
title: "ScrapeCongress_Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ScrapeCong_Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Set up of ScrapeCongress()
```{r eval = FALSE}
# From Github
devtools::install_github('damoncharlesroberts/ScrapeCongress')
library(ScrapeCongress)

# From CRAN
install.packages('ScrapeCongress')
library(ScrapeCongress)

# You need to also need to have your Twitter Developer and App information handy. You will recieve a  prompt in your RStudio Console to enter this information to authenticate you. 

```
To set up a twitter developer account, you must apply on their website: dev.twitter.com. Once your account has been approved, you must create an APP. Once you have created an APP, you can access your API KEY, API secret key, Access Token, and Access token Secret. Each time that you start a new R session and use the ScrapeCongress library, you will need to have your API KEY, API Secret Key, Access Token, Access Token Secret, and the Name of your APP (As it appears on twitter) handy.

You also need to create a data folder in your current working directory. The folder can be empty, just set or find your current working directory and create a folder called 'data' no need for capitalization. This is where all of your CSV's will download to. If you do not do this step, you will run into issues.

## To Start Scraping Tweets use these functions:
```{r eval = FALSE}
senmaleD()
senfemD()
senmaleR()
senfemR()
hormaleD()
horfemD()
hormaleR()
horfemR()
```

These functions will stream the 50 most recent tweets and will download a CSV for each member of Congress and it will then create a new CSV combining all of the tweets from the same Bicameral House, Gender, and Party of the member
