---
title: "ScrapeCongress_Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ScrapeCong_Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Set up of ScrapeCongress()
```{r eval = FALSE}

devtools::install_github('damoncharlesroberts/ScrapeCongress')
library(ScrapeCongress)

# You need to also load your Twitter Developer Credentials and API Keys into your R Script. 

api_key <- "YOUR API KEY HERE"
api_secret <- "YOUR API SECRET KEY HERE"
access_token <- "YOUR ACCESS TOKEN HERE"
access_token_secret <- "YOUR ACCESS TOKEN SECRET HERE"
token <- create_token(
  app = "APP NAME HERE",
  consumer_key = api_key,
  consumer_secret = api_secret,
  access_token = access_token,
  access_secret = access_token_secret
)
```
To set up a twitter developer account, you must apply on their website: dev.twitter.com. Once your account has been approved, you must create an APP. Once you have created an APP, you can access your API KEY, API secret key, Access Token, and Access token Secret. 

## To Start Scraping Tweets use these functions:
```{r eval = FALSE}
senmaleD()
senfemD()
senmaleR()
senfemR()
hormaleD()
horfemD()
hormaleR()
horfemR()
```

These functions will stream the 50 most recent tweets and will download a CSV for each member of Congress and it will then create a new CSV combining all of the tweets from the same Bicameral House, Gender, and Party of the member

To organize the tweets by line, simply run this command

```{r eval = FALSE}
tweet_per_line()
```
